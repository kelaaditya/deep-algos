{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import pool\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class cnn_layer():\n",
    "    def __init__(self, output_activation_func=T.nnet.relu, K_init, b_init, pool_size=(2,2)):\n",
    "        '''\n",
    "        K_init: Initial values for the kernel for this layer\n",
    "        b_init: Initial values for the bias for this layer\n",
    "        activation: RelU\n",
    "        pool_size: size over which max_pool is applied\n",
    "        '''\n",
    "        \n",
    "        self.K = theano.shared(value=K_init.astype(theano.config.floatX),\n",
    "                               borrow=True\n",
    "                              )\n",
    "        self.b = theano.shared(value=b_init.astype(theano.config.floatX),\n",
    "                               borrow=True\n",
    "                              )\n",
    "        \n",
    "        \n",
    "        self.params = [self.K, self.b]\n",
    "    \n",
    "    def output(self, I):\n",
    "        assert I.shape[1] == K_init.shape[1]\n",
    "        self.I = I\n",
    "        \n",
    "        conv_out = T.nnet.conv2d(I, self.K)\n",
    "        pool_out = pool.pool_2d(conv_out, pool_size, ignore_border=True)\n",
    "        \n",
    "        return(output_activation_func(pool_out + self.b.dimshuffle('x', 0, 'x', 'x')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self, n_layer, output_activation_func, K_init, b_init):\n",
    "        '''\n",
    "        output of sequential layers\n",
    "\n",
    "        n_layer: number of convolutional layers\n",
    "        '''\n",
    "        self.layers = [cnn_layer(K_init, b_init) for i in range(n_layer-1)]\n",
    "        self.layers.append(cnn_layer(output_activation_func, K_init, b_init))\n",
    "            \n",
    "        self.params = [item for layer in self.layers for item in layer.params]\n",
    "        #mlp.params is a list of parameters, not a list of lists of parameters\n",
    "    \n",
    "    def output(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.output(X)\n",
    "        return(X)\n",
    "    \n",
    "    def error(self, X, y):\n",
    "        return(T.sum((y-self.output(X))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
