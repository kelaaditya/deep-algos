{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import pool\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class cnn_layer():\n",
    "    def __init__(self, output_activation_func=T.nnet.relu, K_init, b_init, pool_size=(2,2)):\n",
    "        '''\n",
    "        K_init: Initial values for the kernel for this layer\n",
    "        b_init: Initial values for the bias for this layer\n",
    "        activation: RelU\n",
    "        pool_size: size over which max_pool is applied\n",
    "        '''\n",
    "        \n",
    "        self.K = theano.shared(value=K_init.astype(theano.config.floatX),\n",
    "                               borrow=True\n",
    "                              )\n",
    "        self.b = theano.shared(value=b_init.astype(theano.config.floatX),\n",
    "                               borrow=True\n",
    "                              )\n",
    "        \n",
    "        \n",
    "        self.params = [self.K, self.b]\n",
    "    \n",
    "    def output(self, I):\n",
    "        assert I.shape[1] == K_init.shape[1]\n",
    "        self.I = I\n",
    "        \n",
    "        conv_out = T.nnet.conv2d(I, self.K)\n",
    "        pool_out = pool.pool_2d(conv_out, pool_size, ignore_border=True)\n",
    "        \n",
    "        return(output_activation_func(pool_out + self.b.dimshuffle('x', 0, 'x', 'x')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, activation_func=T.nnet.relu, W_init, b_init):\n",
    "        '''\n",
    "        output = activation(WX+b)\n",
    "        X is the data matrix (each column is one example)\n",
    "        W takes 'n_in' inputs from the previous layer (the number of previous layers nodes)\n",
    "        and has 'n_out' outputs (the number of the next layers nodes)\n",
    "        '''\n",
    "        n_out, n_in = W_init.shape\n",
    "        self.W = theano.shared(value=W_init.astype(theano.config.floatX), borrow=True)\n",
    "        #borrow=True as we allow Theano to use memory for this object (make faster)\n",
    "        self.b = theano.shared(value=b_init.reshape(n_out, 1).astype(theano.config.floatX), \n",
    "                               borrow=True, \n",
    "                               broadcastable=(False, True))\n",
    "        self.activation_func = activation_func\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def output(self, X):\n",
    "        '''\n",
    "        Gives the output: activation(WX+b)\n",
    "        '''\n",
    "        pre_activation = T.dot(self.W, X) + self.b\n",
    "        return(self.activation_func(pre_activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
