{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dog v Cat Problem using a CNN + STN\n",
    "A 2 layer convolutional network with a third fully connected layer is combined with a Spatial Transformed Network for object detection.  \n",
    "There are two STN layers, one before the first convolution layer and one before the second convolution layer \n",
    "\n",
    "I modified the original implementation of STN to be compatible with Tensorflow 1.0 \n",
    "\n",
    "The folder UTILS contains:  \n",
    "1. The modified spatial_transformer function in ./utils/\n",
    "2. The function \"batchify\" is for yielding batches of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "\n",
    "from tflearn.data_utils import to_categorical\n",
    "from utils import load_data\n",
    "from utils import spatial_transformer\n",
    "from utils import vgg19\n",
    "from utils import batchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "IMAGE_SIZE = (64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data using the \"load_data\" function in ./utils/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, _ = load_data.load_data('path_to_training_and_test_folder', IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + STN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stn_cnn(X_data, Y_data, image_size, batch_size, epochs):\n",
    "    '''\n",
    "    A CNN network enhanced with Spatial Transformer Networks\n",
    "    \n",
    "    INPUTS:\n",
    "    - X_data     - image data\n",
    "    - Y_data     - classifier data\n",
    "    - image_size - size of the input images\n",
    "    - batch_size - Size of the batches of input data\n",
    "    - epochs     - number of epochs\n",
    "    \n",
    "    OUTPUTS:\n",
    "    - returns the training loss list\n",
    "    '''\n",
    "\n",
    "    def _conv_layer(input_layer, weights, bias):\n",
    "        '''\n",
    "        Creates a convolutional layer\n",
    "\n",
    "        INPUTS:\n",
    "        - input_layer : preceding layer from network\n",
    "        - weights     : filter for the convolution operation\n",
    "        - bias        : bias vector\n",
    "\n",
    "        OUTPUTS:\n",
    "        - returns a bias added convoluted layer \n",
    "        '''\n",
    "        weights = tf.Variable(initial_value=weights, trainable=True, name='conv_weights')\n",
    "        bias = tf.Variable(initial_value=bias, trainable=True, name='conv_bias')\n",
    "        conv_layer = tf.nn.conv2d(input_layer, \n",
    "                                  filter=weights,\n",
    "                                  strides=(1, 2, 2, 1),\n",
    "                                  padding='SAME')\n",
    "        return(tf.nn.bias_add(conv_layer, bias))\n",
    "    \n",
    "    \n",
    "    def _full_layer(input_layer, weights, bias):\n",
    "        '''\n",
    "        Creates a fully connected layer with specified no of units\n",
    "\n",
    "        INPUTS:\n",
    "        - input_layer : preceding layer from network\n",
    "        - no_of_units : number of hidden units for this layer\n",
    "\n",
    "        OUTPUTS:\n",
    "        - returns a fully connected layer with the specified no of units\n",
    "        '''\n",
    "        shape = input_layer.get_shape().as_list()\n",
    "        dim = 1\n",
    "        for d in shape[1:]:\n",
    "            dim *= d\n",
    "        X = tf.reshape(input_layer, [-1, dim])\n",
    "        \n",
    "        weights = tf.Variable(initial_value=weights, trainable=True, name='full_layer_weights')\n",
    "        bias = tf.Variable(initial_value=bias, trainable=True, name='full_layer_bias')\n",
    "        return(tf.nn.bias_add(tf.matmul(X, weights), bias))\n",
    "    \n",
    "    def transform_layer(input_layer, out_size):\n",
    "        '''\n",
    "        Creates a Spatially Transformer Network (STN) layer\n",
    "\n",
    "        INPUTS:\n",
    "        - input_layer : preceding layer from network\n",
    "        - out_size    : the size of the output image\n",
    "\n",
    "        OUTPUTS:\n",
    "        - outputs a Spatially Transformed Layer from the input layer\n",
    "        '''\n",
    "        shape = input_layer.get_shape().as_list()\n",
    "        dim = 1\n",
    "        for d in shape[1:]:\n",
    "            dim *= d\n",
    "        X = tf.reshape(input_layer, [-1, dim])\n",
    "        weights = tf.Variable(tf.random_normal([dim, 6]), trainable=True, name='transform_weights')\n",
    "        bias = tf.Variable(initial_value=np.array([ 1.,  0.,  0.,  0.,  1.,  0.], dtype=np.float32), \n",
    "                           trainable=True, name='transform_bias')\n",
    "        output_layer = tf.nn.relu(tf.nn.bias_add(tf.matmul(X, weights), bias))\n",
    "        output_layer = spatial_transformer.transformer(input_layer, output_layer, out_size)\n",
    "        return(output_layer)\n",
    "    \n",
    "    def _drop_layer(self, input_layer, keep_prob=0.5):\n",
    "        '''\n",
    "        Creates a dropout layer\n",
    "\n",
    "        INPUTS:\n",
    "        - input_layer : preceding layer from network\n",
    "        - keep_prob   : the probability of keeping unit\n",
    "                        default value = 0.5\n",
    "\n",
    "        OUTPUTS:\n",
    "        - outputs a dropout layer\n",
    "        '''\n",
    "        intermediate_layer = tf.nn.relu(input_layer) \n",
    "        return(tf.nn.dropout(intermediate_layer, keep_prob))\n",
    "    \n",
    "    def _relu_layer(input_layer):\n",
    "        '''\n",
    "        Creates a RELU activated layer\n",
    "\n",
    "        INPUTS:\n",
    "        - input_layer : preceding layer from network\n",
    "\n",
    "        OUTPUTS:\n",
    "        - outputs a RELU activated layer\n",
    "        '''\n",
    "        return(tf.nn.relu(input_layer))\n",
    "    \n",
    "    def _pool_layer(input_layer, pool_func='avg'):\n",
    "        '''\n",
    "        Creates a {avg, max}-pool layer\n",
    "\n",
    "        INPUTS:\n",
    "        - 'avg' : Average pooling\n",
    "        - Else  : Max pooling\n",
    "\n",
    "        OUTPUTS:\n",
    "        - 'avg' : An average pooled layer from the input layer\n",
    "        - 'max' : A max pooled layer otherwise\n",
    "        '''\n",
    "        if pool_func == 'avg':\n",
    "            return(tf.nn.avg_pool(input_layer,\n",
    "                                  ksize=(1, 2, 2, 1),\n",
    "                                  strides=(1, 2, 2, 1),\n",
    "                                  padding='SAME'))\n",
    "        else:\n",
    "            return(tf.nn.max_pool(input_layer,\n",
    "                                  ksize=(1, 2, 2, 1),\n",
    "                                  strides=(1, 2, 2, 1),\n",
    "                                  padding='SAME'))\n",
    "    \n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(batch_size, *image_size, 3), name='X')\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 2), name='Y')\n",
    "    \n",
    "    # the first Spatially Transformed Network layer\n",
    "    transformed_layer_1 = transform_layer(X, image_size)\n",
    "    \n",
    "    # we choose the filter size and the bias here\n",
    "    # weight_conv1.shape = (filter_size, filter_size, no_of_channels, no_of_filters)\n",
    "    # bias_conv1.shape = (filter_size, )\n",
    "    conv1_weight = tf.zeros((3, 3, 3, 64), dtype=tf.float32)\n",
    "    conv1_bias = tf.random_normal([64])\n",
    "    conv_layer1 = _conv_layer(transformed_layer_1, conv1_weight, conv1_bias)\n",
    "    relu_layer1 = _relu_layer(conv_layer1)\n",
    "\n",
    "    # the second Spatially Transformed Network layer\n",
    "    transformed_layer_2 = transform_layer(relu_layer1, image_size)\n",
    "    \n",
    "    # we choose the filter size and the bias here\n",
    "    # weight_conv1.shape = (filter_size, filter_size, no_of_filters_conv1, no_of_new_filters)\n",
    "    # bias_conv1.shape = (new_filter_size, )\n",
    "    conv2_weight = tf.zeros((3, 3, 64, 64), dtype=tf.float32)\n",
    "    conv2_bias = tf.random_normal([64])\n",
    "    conv_layer2 = _conv_layer(transformed_layer_2, conv2_weight, conv2_bias)\n",
    "    relu_layer2 = _relu_layer(conv_layer2)\n",
    "\n",
    "    shape = relu_layer2.get_shape().as_list()\n",
    "    dim = 1\n",
    "    for d in shape[1:]:\n",
    "        dim *= d\n",
    "    full_weights = tf.random_normal([dim, 2])\n",
    "    full_biases = tf.random_normal([2])\n",
    "    full_layer1 = _full_layer(relu_layer2, full_weights, full_biases)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=full_layer1, labels=Y))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(1.0).minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        number_batches = int(len(X_data)/batch_size)\n",
    "        training_loss_list = []\n",
    "        for epoch in range(epochs):\n",
    "            for batch in batchify.batchify(X_data, Y_data, batch_size):\n",
    "                X_batch, Y_batch = batch\n",
    "                _, training_loss_value = sess.run([optimizer, loss], feed_dict={X: X_batch, Y: Y_batch})\n",
    "                training_loss_list.append(training_loss_value)\n",
    "    \n",
    "    return(training_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stn_cnn(X_train, Y_train, IMAGE_SIZE, BATCH_SIZE, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
